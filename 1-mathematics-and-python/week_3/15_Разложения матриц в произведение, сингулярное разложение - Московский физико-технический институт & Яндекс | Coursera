Вырезано из https://www.coursera.org/learn/mathematics-and-python/lecture/L9bCV/razlozhieniia-matrits-v-proizviedieniie-singhuliarnoie-razlozhieniie 

Video Player is loading. 

Play Video 

Loaded: 0% 

0:05 

Progress: 0% 

Current Time 0:05 

/ 

Duration 3:59 

Субтитры 

Отключить субтитры 

Русский 

Качество видео 

Среднее 

Скорость воспроизведения 

1.00x 

Автозапуск 

This is a modal window. 

Beginning of dialog window. Escape will cancel and close the window. 

TextColorTransparencyBackgroundColorTransparencyWindowColorTransparency 

Font SizeText Edge StyleFont Family 

End of dialog window. 

Не удалось отправить. Повторите попытку.Пропустить 

В этом видео мы узнаем,  

что такое матричное разложение.  

Идея матричных разложений очень проста.  

Иногда бывает удобно представить матрицу как произведение каких-то других матриц,  

обладающих некоторыми интересными свойствами.  

Первый пример — спектральное разложение матрицы.  

Если матрица X симметрична, то ее можно представить в виде произведения S  

(транспонированное) * D * S, где матрица D диагональная, а матрица S ортогональная.  

Все матрицы имеют тот же размер, что и матрица X.  

Элементы диагональной матрицы неотрицательные и являются собственными  

числами матрицы X.  

Зачем такое может быть нужно?  

Ну, например, часто встречаются функции вида f(y)  

= y (транспонированное) * X * y, где y — некоторый вектор.  

Такие выражения называются квадратичными формами,  

и вы можете их встретить, например, при анализе многомерного  

нормального распределения или при анализе матрицы ковариации.  

С этими объектами вы познакомитесь ближе в уроках про теорию  

вероятности и статистику.  

Оказывается, что если мы воспользуемся спектральным разложением матрицы,  

то мы сможем провести некоторую очень простую замену переменной,  

введя вместо переменной y переменную z = S * y,  

и теперь квадратичная форма будет иметь намного более простой вид.  

Это будет просто взвешенная сумма квадратов координат новой переменной.  

Оказывается, что в таком виде анализировать намного проще.  

Следующий пример — это сингулярное разложение матрицы.  

В этом случае мы представляем матрицу X как произведение трех матриц: U * D * V.  

Матрицы U и V — ортогональные, матрица D — диагональная.  

Но теперь мы не требуем от матрицы X симметричности.  

Геометрический смысл здесь довольно прост.  

Исходная матрица задает некоторое линейное преобразование, и матрицы,  

которые используются в произведении, тоже задают некоторые преобразования.  

И мы просто вместо того чтобы рассматривать какое-то одно сложное  

преобразование, представляем его как сначала некоторое ортогональное  

преобразование, ну то есть какой-нибудь поворот, инверсии, а затем растяжение  

вдоль осей с помощью диагональной матрицы и затем снова поворот.  

Ну то есть повернули, растянули, снова повернули.  

Применений у сингулярного разложения масса.  

На самом деле очень часто, выводя какие-то выражения для разных методов  

машинного обучения, мы будем сталкиваться с тем,  

что подставить сингулярное разложение — это очень хорошая идея,  

которая приводит к каким-нибудь способам избежать разные сложные ситуации.  

Одно из самых колоритных применений  

сингулярного разложения — в рекомендательных системах.  

Если у нас есть матрица, в которой записаны числа, которые являются просто  

оценками фильмов или каких-то других объектов пользователями, то,  

применив сингулярное разложение к этой матрице,  

мы можем построить достаточно неплохие простенькие рекомендации.  

Но об этом мы узнаем подробнее в следующих видео.  

Пока подведем итог.  

Порой бывает удобно представить матрицу как произведение нескольких других матриц,  

которые обладают некоторыми хорошими свойствами.  

Такое представление называется матричным разложением.  

Мы рассмотрели два простых примера: спектральное разложение и  

сингулярное разложение.  

Сингулярное разложение особенно понадобится нам в дальнейшем,  

в частности в рекомендациях.  

А в следующем видео мы познакомимся с еще одной интерпретацией понятия «матричные  

разложения», которое будет еще более приближать нас к применению  

матричных разложений в рекомендациях.  
