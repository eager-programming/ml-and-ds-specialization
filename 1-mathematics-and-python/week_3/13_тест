Вырезано из https://www.coursera.org/learn/mathematics-and-python/exam/oQMkM/mietody-optimizatsii-v-nieghladkikh-zadachakh 

Вопрос 1 

Правильно 

1 из 1 

Баллы 

Какие из перечисленных подходов к задаче поиска минимума не требуют существования градиента у оптимизируемой функции? 

Метод градиентного спуска. 

правильно, этот вариант не должен быть выбран  

Дифференциальная эволюция. 

Правильно  

Новые точки в методе выбираются без учета градиента. 

Метод имитации отжига. 

Правильно  

Новые точки в методе выбираются без учета градиента. 

Аналитическое нахождение точки минимума с помощью необходимого условия экстремума. 

правильно, этот вариант не должен быть выбран  

Вопрос 2 

Правильно 

1 из 1 

Баллы 

2. Вопрос 2 

Как вы думаете, зачем нужна стадия мутации в генетических алгоритмах? 

Чтобы с большей точностью двигаться на каждом шаге по градиенту сглаженной функции. 

Чтобы лучше попадать в локальные минимумы. 

Чтобы популяция не вырождалась слишком быстро в набор очень похожих друг на друга векторов и был некоторый шанс выбивания из локальных минимумов. 

Правильно  

Верно!  

Вопрос 3 

Правильно 

1 из 1 

Баллы 

3. Вопрос 3 

Почему при поиске минимума методом имитации отжига допускаются переходы в точки, в которых функция принимает большие значения, нежели в текущей? 

Чтобы метод быстрее сходился. 

Чтобы метод мог иногда выбираться из локальных минимумов. 

Правильно  

Верно! И это преимущество данного метода по сравнению с градиентным. 

Чтобы более точно моделировать физический процесс отжига. 

Вопрос 4 

Правильно 

1 из 1 

Баллы 

4. Вопрос 4 

В каких случаях стоит применять методы оптимизации, не использующие градиент? 

Во всех случаях, т.к. очень часто неградиентные методы сходятся быстрее градиентных. 

В случаях, когда у функции нет градиента. А также в случаях, когда нужно найти глобальный экстремум функции, а градиентные методы скорее всего будут попадать в локальный. 

Правильно  

Верно! Так как в случае наличия градиента скорее всего неградиентному методу потребуется больше итераций или вычислений значения функции, чем градиентному. 
