Вырезано из https://www.coursera.org/learn/supervised-learning/lecture/IPObE/obiedinieniie-tochnosti-i-polnoty 

Интерактивный текст видеоматериала 

[заставка без звука] В этом видео мы поговорим о том,  

как объединить точность и полноту в одну метрику качества классификации.  

В прошлый раз мы выяснили, что точность показывает,  

насколько мы можем доверять классификатору в случае, если он срабатывает.  

То есть в случае, если он относит объект к первому классу.  

Полнота же измеряет, как много объектов первого класса наш классификатор выделил,  

на скольки из них он сработал.  

При этом есть задачи, где имеет место ограничение на одну из этих метрик,  

например, точность должна быть не меньше 95 %.  

И при этом мы будем оптимизировать другую метрику, например, полноту.  

Но при этом, точность и полнота хороши сами по себе, например, тем,  

что они более выразительны на несбалансированных выборках.  

И у нас может просто возникнуть желание максимизировать и точность, и полноту  

одновременно, но, при этом максимизировать две метрики, это не очень удобно.  

Лучше сначала объединить их в одну.  

Давайте выясним, как это правильно сделать.  

Первый подход, который мы обсудим, это арифметическое среднее.  

Просто сложим точность и полноту и поделим на 2.  

Чтобы визуализировать данный подход к их усреднению,  

мы будем рисовать линии уровня.  

По оси x мы будем откладывать точность, по оси y — полноту, и рисовать линии уровня,  

то есть линии, на которых арифметическое среднее принимает одно и то же значение.  

Давайте разберём простой пример.  

Представьте, что у нас есть алгоритм,  

у которого точность равна 10 %, а полнота — 100 %.  

На самом деле, это может быть выборка,  

в которой всего 10 % положительных объектов и алгоритм,  

который абсолютно на всех объектах выдаёт ответ +1, константный алгоритм.  

Понятно, что он бесполезен.  

Среднее арифметическое точности и полноты в этом случае = 55 %.  

А вот другой алгоритм.  

У него точность и полнота = 55 %.  

Этот алгоритм гораздо лучше предыдущего,  

но при этом среднее арифметическое снова = 55 %.  

Эти два алгоритма лежат на одной линии уровня.  

Это очень плохо.  

Константный и разумный алгоритмы получают один и тот же показатель.  

Чтобы устранить эту проблему, приходит в голову следующая идея.  

Раз мы хотим одновременно максимизировать и точность,  

и полноту, давайте максимизировать минимум из них.  

В этом случае линии уровня будут выглядеть как-то так.  

Видно, что они сильнее концентрируются в правом верхнем углу,  

то есть там, где находится алгоритм с точностью и полнотой, = 1.  

Данный подход с взятием минимума из точности и полноты решает проблему,  

которую мы обсуждали чуть раньше.  

Если взять алгоритм с точностью 5 % и полнотой 100 %, то минимум будет = 5 %.  

При этом есть другой нюанс.  

Рассмотрим два алгоритма, оба из которых имеют точность 40 %,  

но при этом полнота первого = 50 %, а полнота второго = 90 %.  

Понятно, что второй алгоритм лучше.  

При такой же точности он даёт более высокую полноту,  

но при этом и минимум и там, и там = 40 %.  

Они снова лежат на одной линии уровня, хотя этого не должно быть.  

Чтобы устранить проблему, давайте попробуем сгладить минимум.  

Это можно сделать с помощью гармонического среднего или F-меры.  

Чтобы её посчитать, нужно вычислить дробь, в числителе которой стоит произведение  

точности и полноты, умноженное на 2, а в знаменателе сумма точности и полноты.  

Если мы рассматриваем два алгоритма, оба из которых имеют точность 40 %,  

и при этом первый имеет полноту 50 %, а второй — 90 %,  

то у первого F-мера = 44 %, а у второго — 55 %.  

Второй оказывается на линии уровня,  

которая ближе к правому верхнему углу, ближе к идеальному классификатору.  

При этом, если вы хотите отдать предпочтение либо точности, либо полноте,  

можно воспользоваться расширенной версией F-меры, который имеет параметр β.  

Она вычисляется по такой страшной формуле.  

При этом, если вы возьмёте β = 0.5, то важнее окажется полнота.  

Дело в том, что если вы зафиксируете полноту и будете менять точность,  

то данная F-мера будет меняться довольно гладко.  

Если же вы зафиксируете точность и будете менять полноту,  

изменения будут очень резкие.  

Таким образом, полнота важнее в этом случае.  

Если же взять β = 2, то ситуация поменяется.  

Важнее окажется точность.  

Поскольку при фиксированной полноте изменение точности будет гораздо  

сильнее приводить к перемене F-меры.  

Итак, мы обсудили,  

что лучший способ объединения точности и полноты в одну метрику, это F-мера,  

которая представляет собой сглаженную версию минимума из точности и полноты.  

При этом, если вы хотите отдать предпочтение либо точности,  

либо полноте при усреднении, можно воспользоваться параметром β в F-мере.  

В следующем видео мы поговорим о том,  

как измерять качество оценок принадлежности тому или иному классу.  
