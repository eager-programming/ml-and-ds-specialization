Вырезано из https://www.coursera.org/learn/supervised-learning/lecture/GhyDw/probliema-pierieobuchieniia 

Интерактивный текст видеоматериала 

[БЕЗ_ЗВУКА] Мы начинаем урок,  

посвящённый проблеме переобучения и вопросу оценивания качества алгоритмов.  

По итогам этого урока вы будете понимать, как оценить качество алгоритма на новых  

неизвестных данных, а также как сравнить много алгоритмов и выбрать из них лучший.  

А начнём урок мы с того, что разберёмся с тем, что такое переобучение,  

и почему это очень плохо.  

Давайте рассмотрим простой пример.  

Допустим, мы решаем задачу классификации и построили некоторый алгоритм,  

например, линейный классификатор, и измеряем долю ошибок на обучающей выборке.  

Допустим, она получилась 0.2,  

то есть мы допускаем ошибку на двадцати процентах объектов обучающей выборки.  

Предположим, что нас это устроило, и мы используем этот алгоритм дальше.  

Но как понять из того, что у него небольшая доля ошибок на обучении,  

извлёк ли он закономерности, может ли он хорошо работать на новых данных?  

На самом деле, никаких гарантий нет.  

Легко может оказаться, что мы возьмём новую выборку,  

применим к ней наш уже обученный алгоритм и получим, что доля ошибок на  

новой выборке равна 0.9, то есть алгоритм ошибается на 90 % объектов.  

Это никуда не годится.  

Значит, что алгоритм не смог обобщить обучающую выборку, не смог извлечь  

из него закономерности и применить эти знания для классификации новых объектов.  

Но при этом, заметьте, что мы получили хорошее качество на обучении.  

То есть алгоритм как-то смог подогнаться под обучение,  

не извлекая из него закономерностей.  

Эта проблема и называется переобучение.  

Чтобы чуть лучше понять, в чём заключается переобучение,  

давайте рассмотрим классический пример про линейную регрессию.  

Итак, рассмотрим некоторую выборку.  

Объекты выборки обозначены синими точками, это одномерная выборка и сдача регрессии.  

По оси x отложено значение признака, по оси y — значение ответа.  

Истинная зависимость между ответом и признаком выглядит как зелёная кривая.  

Видно, что это такая нелинейная зависимость с двумя экстремумами.  

И давайте будем пробовать разные модели,  

с помощью которых будем пытаться предсказывать ответы.  

И начнём мы с константной регрессии,  

то есть алгоритм a(x) будет иметь вид w0, где w0 — некоторая константа.  

Настроив эту модель под данные, мы получим некоторую красную горизонтальную прямую,  

которая видно, что никуда не годится: она довольно плохо обобщает информацию.  

Эта проблема называется недообучением.  

Мы не смогли построить хороший алгоритм из-за того,  

что семейство алгоритмов слишком простое, оно не может уловить закономерности.  

Понятно, что решением является усложнение семейства алгоритмов.  

Хорошо, давайте рассмотрим линейную регрессию,  

то есть алгоритмы вида w0 + w1 * x.  

Настроив такой алгоритм под нашу выборку, мы всё ещё недообучимся.  

Видно, что получилось чуть лучше,  

но красная прямая всё ещё довольно плохо описывает наши данные,  

потому что она является линейной, а закономерность является нелинейной.  

Хорошо, давайте возьмём многочлен третьей степени.  

То есть алгоритм вида w0 + w1 * x + w2 * x² + w3 * x³, — многочлен третьей степени.  

Настроив его на нашу выборку, мы увидим, что полученный алгоритм,  

то есть красная кривая, очень хорошо приближает истинную зависимость.  

Скорее всего, нас устраивает такая модель.  

Мы её и оставим, будем ей пользоваться.  

Но при этом, смотрите, совпадение между красными и зелёными кривыми неидеальное.  

Что если ещё чуть-чуть усложнить алгоритм?  

Может, мы получим ещё более качественную модель.  

Хорошо, давайте возьмём многочлен девятой степени.  

И в этом случае мы получим вот такую закономерность.  

Видно, что восстановленная зависимость, красная кривая, — очень плохая.  

Да, она даёт идеальные ответы на всех объектах обучающей выборки,  

она проходит через все синие точки.  

Но при этом в любой другой точке ответ никуда не годится.  

Эти ответы никак не соответствуют истинной зелёной зависимости.  

Это является переобучением.  

Алгоритм слишком сильно подогнался под обучающую выборку ценой того,  

что он будет давать плохие ответы на новых точках.  

Итак, мы выяснили, что недообучение — это проблема,  

в которой алгоритм имеет плохое качество и на обучающей выборке, и на новых данных.  

А переобучение — это проблема, при которой алгоритм имеет хорошее качественной  

обучение, но плохое качество о новых данных.  

При этом с недообучением понятно как бороться: нужно усложнять семейство  

алгоритмов, брать более сложные алгоритмы, например,  

многочлены высокой степени вместо линейных.  

А вот с переобучением всё сложнее.  

Дело в том, что хороший алгоритм,  

который хорошо обобщает информацию, будет иметь хорошее качественное обучение.  

Переобученный алгоритм тоже будет иметь хорошее качество на обучающей выборке.  

Отличаются они только по качеству на новых данных.  

Хороший алгоритм будет хорошо работать в новых данных, а переобученный — плохо.  

Получается, что, имея лишь обучающую выборку, а мы имеем  

лишь её в момент настройки алгоритма, мы не можем понять, переобучился он или нет.  

Нам нужна какая-то дополнительная информация или дополнительные данные,  

чтобы выявить переобучение.  

Мы приходим к нескольким подходам к выявлению переобучения.  

Например, можно откладывать часть выборки, не использовать её при обучении,  

и дальше уже обученный алгоритм проверять на этой отложенной выборке.  

Или, например, есть кросс-валидация — это усложнённая версия отложенной выборки,  

о которой мы будем говорить в этом уроке.  

Также есть некоторые меры сложности модели, которые позволяют без  

дополнительной выборки понять, получилась ли модель слишком сложной или нет.  

Об этом мы и поговорим в следующем видео.  

И в качестве небольшой затравки давайте посмотрим, что получилось,  

когда мы настраивали многочлен девятой степени.  

Заметьте, что, по сути,  

обучение такого многочлена — это обучение линейной регрессии над признаками x,  

x в квадрате, и так далее, до x в девятой степени, то есть над девятью признаками.  

И если посмотреть на веса модели, которая получилась, окажется,  

что порядок весов очень большой — это миллионы и десятки миллионов.  

Если же посмотреть на порядок весов в модели третьей степени (в многочлене  

третьей степени), которая хорошо подходила под данные, можно увидеть,  

что там порядок гораздо ниже.  

Таким образом, наверное, абсолютные значения весов как-то говорят о том,  

насколько сложная модель у нас получилась.  

Итак, мы с вами выяснили, что переобучение — это проблема,  

которая состоит в излишней подгонке алгоритма под обучающую выборку,  

из-за чего страдает его качество на новых данных.  

Также мы выяснили, что одним из симптомов переобучения линейных моделей являются  

большие веса в этих моделях, что мы будем использовать в следующем уроке, когда  

будем говорить про регуляризацию — способ борьбы с переобучением в линейных методах.  
