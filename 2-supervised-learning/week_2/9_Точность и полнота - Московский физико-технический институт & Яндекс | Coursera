Вырезано из https://www.coursera.org/learn/supervised-learning/lecture/vvgeh/tochnost-i-polnota 

Интерактивный текст видеоматериала 

В этом видео мы поговорим о точности и полноте,  

метриках качества классификации, которые позволяют учитывать разные цены ошибок.  

В прошлом видео мы выяснили, что цены ошибок действительно могут быть разные.  

Например, в случае с кредитным скорингом непонятно,  

что лучше: выдать кредит плохому клиенту, который не вернёт кредит,  

или не выдать кредит хорошему клиенту, который мог бы вернуть этот кредит.  

То, какая ошибка лучше или хуже, какая важнее, какая нет,  

зависит от конкретной стратегии банка.  

Цена этой ошибки может варьироваться.  

Доля верных ответов неспособна учитывать цены разных ошибок.  

Чтобы рассуждать о том, у какой ошибки какая цены, удобно  

ввести матрицу ошибок, которая производит некоторую классификацию типов ошибок.  

Она состоит из двух строк и двух столбцов.  

Строка зависит от того, какой ответ выдаёт наш алгоритм, наша модель.  

Первая строка соответствует объектам, которых наша модель относит к классу +1.  

Вторая строка соответствует объектам, которых наша модель относит к классу -1.  

Столбец зависит от того, к какому классу на самом деле относится объект.  

Если объект относится к классу 1, он попадает в первый столбец.  

Если объект относится к классу -1, он попадает во второй столбец.  

Когда алгоритм относит объект к классу +1,  

будем говорить, что алгоритм срабатывает, он делает срабатывание.  

Итак, если алгоритм сработал, отнёс объект к классу +1,  

и объект действительно относился к классу +1,  

это верное срабатывание или True Positive.  

Если алгоритм сработал, но объект не относился к первому классу,  

на самом деле он из класса -1, то это ложное срабатывание или False Positive.  

Если алгоритм выдаёт ответ -1, будем говорить, что он пропускает объект.  

Итак, если имеет место пропуск, но при этом объект относится к классу 1,  

то это ложный пропуск или False Negative.  

Если же алгоритм пропускает объект, и, действительно,  

этот объект относится к классу -1, то это верный пропуск или True Negative.  

Таким образом, у нас есть два вида ошибок: ложные срабатывания и ложные пропуски.  

И для каждой из них нужна своя метрика качества,  

чтобы как-то измерить, какое количество таких ошибок мы допускаем.  

Давайте будем разбирать наши метрики на двух примерах, на примере двух моделей.  

Будем считать, что у нас выборка состоит из двухсот объектов,  

из которых сто относится к классу 1, и сто относится к классу -1,  

при этом первая модель относит к классу 1 сто объектов,  

из которых 80 — это верное срабатывание и 20 — это ложное срабатывание.  

Вторая модель срабатывает на пятидесяти объектах.  

Из них 48 — это верное срабатывание, а 2 — это ложное срабатывание.  

Первая метрика, о которой мы поговорим — это точность или precision.  

Она показывает, насколько мы можем доверять классификатору в случае,  

если он срабатывает.  

В случае, если он относит объект к первому классу.  

Формально точно задаётся как отношение числа  

верных срабатываний к общему числу срабатываний,  

то есть число верных срабатываний плюс число ложных срабатываний.  

True Positive плюс False Positive.  

Давайте посчитаем точность в нашем примере.  

В случае с первой моделью, она срабатывает на ста объектах,  

и из них 80 действительно относятся к первом классу.  

Значит, нам нужно 80 поделить на сто.  

Получаем 0.8.  

Точность первого алгоритма = 0.8 или 80 процентам.  

Вторая модель срабатывает на пятидесяти объектах,  

и из них 48 — это верные срабатывания.  

Её точность равняется 48 поделить на 50 или 0.96.  

Её точность гораздо выше, она равняется 96 %.  

Если вторая модель срабатывает, то мы можем быть с большой долей  

вероятности уверены, что это срабатывание верное.  

Вторая метрика — это полнота или recall.  

Она показывает, как много истинных объектов первого класса  

алгоритм выделяет, на скольки из них он срабатывает.  

Формально она задаётся как отношение числа верных срабатываний к общему  

числу объектов первого класса выборки,  

то есть число верных срабатываний плюс число ложных пропусков.  

Посчитаем полноту для наших двух моделей.  

К первому классу относится сто объектов.  

И первая модель срабатывает на 80 из них, значит её полнота равна 0.8 или 80 %.  

Вторая модель срабатывает лишь на 48 положительных объектах.  

Таким образом, её полнота равняется 48 поделить на сто или 0.48.  

Вторая модель очень точная, но из-за этого страдает её полнота,  

она выделяет далеко не все объекты первого класса.  

Давайте разберём два примера того,  

как можно пользоваться точностью и полнотой в совокупности.  

Первый пример про кредитный скоринг.  

Представьте, что руководство банка решило, что, если среди всех  

выданных кредитов не более 5 % будут ошибочными,  

то есть лишь 5 % из них не вернут, то такая схема не будет убыточной.  

Эти невозвращённые кредиты не дадут нам слишком много убытков.  

Таким образом, мы получаем ограничение на точность в 0.95.  

Точность должна быть ≥, чем 0.95.  

И при таком ограничении мы будем максимизировать полноту,  

то есть стараться выдать кредиты как можно большему количеству хороших заёмщиков.  

Второй пример про медицинскую диагностику.  

Представьте, что мы сделали модель, хотим сделать модель,  

которая определяет: есть или нет то или иное заболевание у пациента.  

При этом наш заказчик требует, чтобы среди всех протестированных пациентов  

мы выделили как минимум 80 % тех, которые действительно имеют это заболевание.  

Таким образом, мы получаем ограничение,  

что полнота должна быть не меньше, чем 80 %.  

И при этом ограничении мы будет максимизировать точность,  

то есть пытаться сделать как можно меньше число ложных срабатываний.  

Наконец, обратите внимание,  

как точность и полнота работают на несбалансированных выборках.  

Представьте, что у нас есть выборка, в которой сто объектов первого класса и  

более десяти тысяч объектов отрицательного класса, -1 класса.  

При этом у нас 10 верных срабатываний, 20 ложных срабатываний и 90 ложных пропусков.  

Доля верных ответов на данной выборке равняется 99 %.  

Скорее всего, это число ни о чём не говорит.  

Чтобы понять, что плохого с данным алгоритмом,  

нужно померить точность и полноту.  

Давайте измерим точность.  

Всего алгоритм срабатывает на тридцати объектах,  

и из них лишь 10 — это верные срабатывания, значит точность равна 33 %.  

Видно, что алгоритм делает слишком много ложных срабатываний — 66 %.  

Далее полнота.  

Всего в выборке сто объектов первого класса,  

из их них лишь на 10 алгоритм срабатывает.  

Таким образом, полнота равняется 10 %.  

Видно, что у него также много ложных пропусков.  

Он пропускает 90 % объектов первого класса.  

Благодаря точности и полноте мы можем видеть,  

что не так с этим алгоритмом и что можно пытаться улучшить.  

Итак, мы с вами ввели матрицу ошибок и на её основе определили две  

метрики качества: точность и полноту.  

Точность измеряет, как много у нас ложных срабатываний,  

а полнота — как много ложных пропусков.  

И можно отдавать предпочтение одной или другой в зависимости от специфики задачи.  

Также мы выяснили, что точность и полнота могут быть очень полезными в случаях  

со сбалансированными выборками.  

В следующем видео мы поговорим о том,  

как можно объединить точность и полноту в одну метрику качества.  
