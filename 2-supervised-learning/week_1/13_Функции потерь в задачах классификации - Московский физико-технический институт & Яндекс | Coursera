Вырезано из https://www.coursera.org/learn/supervised-learning/lecture/2AzdX/funktsii-potier-v-zadachakh-klassifikatsii 

Интерактивный текст видеоматериала 

[БЕЗ_ЗВУКА] В этом видео мы  

поговорим о том, как измерять качество алгоритмов классификации,  

и в частности линейных классификаторов.  

Как мы уже выяснили,  

линейный классификатор строит гиперплоскость в признаковом пространстве,  

и те объекты, которые находятся с одной стороны от нее, относят к классу −1,  

те объекты, которые находятся с другой стороны от нее, относят к классу +1.  

А как измерить качество работы такого алгоритма?  

В случае с регрессией мы выясняли, что есть много способов измерить ошибку.  

Например, можно взять ответ алгоритма a,  

истинный ответ y, посчитать их разность и возвести это в квадрат.  

Получим квадратичное отклонение.  

Мы говорили, что его удобно оптимизировать, потому что оно гладкое.  

Или можно взять модуль отклонения прогноза от истинного ответа,  

это абсолютное отклонение, которое кажется чуть более логичным, в нем нет квадрата,  

который непонятно зачем, но при этом оно не гладкое,  

его сложнее оптимизировать градиентными методами.  

Есть и другие способы.  

Их много, потому что есть много способов измерить отклонение одного вещественного  

числа от другого.  

При этом довольно странно требовать точного совпадения прогнозов и  

истинных ответов на всей выборке.  

Прогнозов и истинных ответов очень много, их континуум — это вещественные числа,  

и, скорей всего, не получится сделать алгоритм,  

который точно угадывает истинный ответ на каждом объекте, а если и угадывает,  

скорей всего, он слишком точно подогнался под данные,  

он переобучился, мы будем говорить о проблеме переобучения чуть дальше.  

В случае же с классификацией все гораздо проще.  

У нас есть конечное число классов, их k штук,  

и алгоритм тоже выдает один из k классов.  

И при этом у него вполне понятная цель, он должен выдать истинный класс,  

угадать класс объекта и не выдать никакой другой.  

Значит, измерить качество можно с помощью доли неправильных ответов.  

Как она считается?  

Мы берем объект xi-тое, смотрим класс,  

который предсказывает алгоритм a, то есть a(xi-того) и проверяем,  

этот ответ совпадает с истинным ответом yi-тое или не совпадает?  

Если совпадает — записываем 0, если не совпадает — записываем 1.  

И далее мы усредняем эти нолики и единички по всей выборке x.  

Чем меньше это значение, тем меньше доля неправильных ответов,  

тем лучше алгоритм, тем правильнее он работает на выборке.  

Следственно, это нужно минимизировать.  

Получается очень простой и понятный функционал.  

Кстати, заметьте, что его можно переписать в чуть более удобном виде.  

По сути,  

этот индикатор отвечает на вопрос: ошибается ли алгоритм на объекте xi-тое?  

Давайте вспомним, что мы в прошлом видео ввели понятие отступа, которое как раз  

позволяет понять, ошибается алгоритм на объекте или не ошибается.  

Если алгоритм ошибается на i-том объекте, то отступ меньше нуля.  

Получается, что долю неправильных ответов можно переписать как среднее  

по всем индикаторам того, что отступ на объекте меньше нуля.  

Теперь давайте посмотрим,  

как выглядит этот индикатор как функция от отступа.  

Это пороговая функция, пороговая функция потерь.  

Заметьте, что она имеет разрыв в нуле, если отступ меньше нуля,  

то значение этой функции 1, если отступ больше нуля — значение функции 0.  

Из-за этого разрыва нельзя оптимизировать этот функционал градиентными методами,  

все становится немножко сложно.  

В общем-то,  

на самом деле доля неправильных ответов слишком плохой функционал.  

Он разрывный, его нельзя оптимизировать с помощью градиентного спуска.  

Конечно, можно использовать методы негладкой оптимизации, которые вы изучали  

в прошлом курсе, например метод Нелдера – Мида, но при этом это довольно громоздкий,  

тяжелый метод, у которого к тому же нет гарантии, что он сойдется к минимуму.  

При этом такой функционал имеет, скорее всего, много локальных минимумов,  

и нет гарантии, что мы найдем лучший из них, найдем глобальный.  

Поэтому давайте немножко все-таки поработаем над долей неправильных ответов,  

чтобы привести ее к более удобному для градиентной оптимизации виду.  

В первую очередь давайте попробуем что-то сделать с индикатором ошибки,  

с пороговой функцией потерь.  

Давайте оценим ее сверху, то есть построим такую функцию L с волной,  

которая не меньше нуля, если алгоритм дает правильный ответ на объекте,  

и не меньше 1, если алгоритм ошибается на объекте.  

То есть это верхняя оценка на пороговую функцию потерь.  

При этом будем требовать, чтобы эта оценка L с волной была гладкой,  

то есть чтобы ее можно было оптимизировать градиентными методами.  

Используя эту оценку для ошибки на одном объекте,  

можно оценить весь функционал ошибки.  

Эта оценка на функционал ошибки будет выглядеть как среднее значение наших  

гладких оценок на каждом объекте.  

Заметьте, что мы передаем в оценку 2 числа: прогноз алгоритма a на  

объекте xi-тое и истинный ответ yi-тое на этом объекте.  

После того как вы построили эту оценку на  

функционал ошибки, мы будем ее минимизировать.  

При этом обратите внимание,  

мы минимизируем верхнюю оценку (ее удобно минимизировать — она гладкая),  

но при этом нашей задачей является минимизация доли ошибок.  

И мы надеемся, что если мы сделаем верхнюю оценку маленькой,  

то и доля ошибок будет маленькой, но при этом, разумеется, это не гарантируется.  

То есть уже могут возникнуть некоторые проблемы: мы можем сделать маленькой  

оценку, но при этом доля ошибок будет нас не устраивать,  

но зато мы получаем удобный метод оптимизации.  

Здесь приведены некоторые распространенные примеры таких верхних оценок.  

Первая из них — логистическая, вычисляется как натуральный логарифм,  

под которым стоит 1 плюс экспонента от произведения ответа алгоритма истинного  

ответа с минусом.  

Также есть экспоненциальная оценка и кусочно-линейная.  

Логистическая используется в логистической регрессии, о которой вы узнаете в  

следующих уроках; кусочно-линейная — в методе опорных векторов.  

Заметьте, что все 3 оценки на самом деле зависят не по  

отдельности от прогноза алгоритма a и истинного ответа y,  

а от их произведения y × a, это нам пригодится чуть дальше.  

Хорошо, давайте рассмотрим конкретный пример.  

Возьмем логистическую функцию потерь и посмотрим на верхнюю оценку на  

функционал ошибки, которая получается при использовании этой функции потерь.  

Она будет выглядеть вот так.  

Функция потерь уже получилась гладкой,  

что гораздо приятнее, но все еще есть проблема.  

В этой функции есть функция знака, и вектор весов, а именно по нему  

нам нужно минимизировать этот функционал, вектор весов стоит под функцией знака.  

Функция знака является дискретной и разрывной,  

и из-за этого оптимизация по вектору весов все еще будет сложной.  

Значит, нужно что-то и с этим сделать,  

чтобы можно было использовать градиентные методы.  

Окей.  

Давайте еще раз рассмотрим нашу верхнюю оценку,  

которая усредняет наши функции L с волной, и при этом в функцию L с волной передается  

прогноз алгоритма, то есть знак скалярного произведения, и истинный ответ yi-тое.  

И давайте сделаем то, что в методах оптимизации иногда называют релаксацией.  

Мы уберем функцию знака и будем передавать в нашу функцию потерь L с волной значение  

скалярного произведения вектора весов на вектор признаков и истинный ответ.  

То есть будем измерять качество оценки, качество скалярного произведения.  

В этом случае, например, логистическая функция потерь будет выглядеть вот так.  

Заметьте, что теперь внутри нее стоит не знак от скалярного произведения,  

а просто произведение истинного ответа yi-тое на  

скалярное произведение w на xi-тое, то есть, по сути, отступ.  

И можно показать, что минимизация этой функции потерь приведет к тому,  

что мы будем максимизировать отступ на каждом объекте, то есть пытаться сделать  

его положительным, сделать правильную классификацию на каждом объекте,  

а даже если мы уже делаем правильную классификацию на каждом объекте,  

будем стремиться максимизировать отступ, то есть максимизировать уверенность  

классификации на каждом объекте, что довольно хорошо.  

Итак, чтобы добиться гладкости функции потерь,  

которую мы теперь можем оптимизировать, мы сделали два шага.  

Во-первых, мы заменили пороговую функцию потерь на некоторую ее гладкую верхнюю  

оценку, а также провели релаксацию, то есть заменили произведение  

истинного ответа на бинарный ответ алгоритма на отступ, то есть произведение  

истинного ответа на скалярное произведение вектора весов на вектор признаков.  

Теперь можно использовать любые методы оптимизации,  

чтобы обучать линейный классификатор.  

Например, стохастический градиентный спуск.  

Вы можете легко посчитать частные производные для любого  

функционала и дальше запустить нашу стандартную процедуру.  

Итак, что мы обсудили?  

Мы выяснили, что в задаче классификации есть вполне  

логичный функционал потерь — это доля ошибок, доля неправильных ответов.  

Но при этом он является негладким, его сложно оптимизировать,  

и поэтому нужно сделать 2 шага, чтобы оптимизировать было удобнее.  

Во-первых, оценить сверху пороговую функцию потерь чем то гладким, и,  

во-вторых, провести релаксацию,  

то есть заменить индикатор ошибки на отступ на данном объекте.  

Далее можно для обучения использовать любые градиентные методы или другие ваши  

любимые методы оптимизации.  

На этом урок про линейные модели заканчивается,  

и также заканчивается первый модуль.  

А следующий модуль мы начнем с того, что обсудим проблему переобучения — одну  

из центральных проблем анализа данных, и поговорим о том, как с ней бороться.  
